# RAWRE Backend Architecture: Data Flow & Embedding Usage

## ğŸ¯ Executive Summary

**ISSUE IDENTIFIED**: Embeddings are generated and stored but **NOT being used** for semantic search. The system falls back to basic keyword matching, which significantly reduces the intelligence of shot selection.

---

## ğŸ“Š Current Architecture Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          INGESTION PHASE                             â”‚
â”‚                     (ingest/orchestrator.py)                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â–¼                           â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚  Video Processor â”‚        â”‚ Gemini Analyzer  â”‚
         â”‚   (FFmpeg/CV2)   â”‚        â”‚ (Visual AI)      â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚                           â”‚
                    â”œâ”€â”€â”€â–º Frame Extraction     â”‚
                    â”œâ”€â”€â”€â–º Shot Detection       â”‚
                    â””â”€â”€â”€â–º Timecode Mapping     â”‚
                                               â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
                    â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚     Transcriber (Whisper)     â”‚
         â”‚  - Generates ASR text         â”‚
         â”‚  - Timestamp alignment        â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
                    â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚  Embedder (sentence-trans)   â”‚
         â”‚  âœ“ Text embeddings (384d)    â”‚
         â”‚  âœ“ Visual embeddings (512d)  â”‚
         â”‚  âœ“ CLIP for images           â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
                    â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚         STORAGE              â”‚
         â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
         â”‚ SQLite Database:             â”‚
         â”‚  - Shot metadata             â”‚
         â”‚  - Transcripts               â”‚
         â”‚  - Gemini descriptions       â”‚
         â”‚  - Embeddings (BLOB)         â”‚
         â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
         â”‚ FAISS Vector Index:          â”‚
         â”‚  - Text embeddings index     â”‚
         â”‚  - Visual embeddings index   â”‚
         â”‚  - Fast similarity search    â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        COMPILATION PHASE                             â”‚
â”‚                     (agent/orchestrator.py)                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

    User Request: Brief + Target Duration
                    â”‚
                    â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚    Working Set Builder   â”‚
         â”‚  (agent/working_set.py)  â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â–¼                       â–¼
    âŒ SHOULD USE:          âœ… ACTUALLY USES:
  Vector Similarity        Keyword Matching
  (semantic search)        (Jaccard similarity)
        â”‚                       â”‚
        â”‚                       â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
                    â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚   Working Set (50-100    â”‚
         â”‚   shots with context)    â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
                    â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚          AGENT LOOP                   â”‚
    â”‚  (max 3 iterations for refinement)    â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â–¼           â–¼           â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Plan â”‚   â”‚ Pick â”‚   â”‚ Verify   â”‚
    â”‚ Agentâ”‚â”€â”€â†’â”‚ Agentâ”‚â”€â”€â†’â”‚ Agent    â”‚
    â”‚      â”‚   â”‚      â”‚   â”‚          â”‚
    â”‚Claudeâ”‚   â”‚Claudeâ”‚   â”‚Claude    â”‚
    â””â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚           â”‚           â”‚
        â”‚           â”‚           â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
          Score â‰¥ 7.0/10? â”€â”€Noâ”€â”€â”
                    â”‚             â”‚
                   Yes           Loop
                    â”‚             â”‚
                    â–¼             â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
         â”‚   EDL Output     â”‚â—„â”€â”€â”€â”˜
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ” Detailed Component Analysis

### 1. Ingestion: What Works Well âœ…

**Files**: `ingest/orchestrator.py`, `ingest/embedder.py`, `ingest/gemini_analyzer.py`

**Process**:
```python
# For each video shot:
1. Extract keyframe â†’ CLIP visual embedding (512d)
2. Transcribe audio â†’ Whisper ASR text
3. Embed transcript â†’ SentenceTransformer (384d)
4. Analyze visually â†’ Gemini description
5. Store everything in SQLite + FAISS index
```

**Data Stored Per Shot**:
- `embedding_text`: 384-dimensional vector (from transcript)
- `embedding_visual`: 512-dimensional vector (from keyframe)
- `asr_text`: Full transcript
- `gemini_description`: Visual analysis
- `gemini_shot_size`: Wide/Medium/Close
- `gemini_subjects`: People/objects in frame
- `duration_ms`, `tc_in`, `tc_out`

**âœ… This part is excellent** - rich multimodal embeddings are generated.

---

### 2. Working Set Builder: THE PROBLEM âŒ

**File**: `agent/working_set.py`

**What SHOULD Happen**:
```python
def build_for_query(story_slug, query, max_shots=50):
    # 1. Embed the user's query
    query_embedding = embedder.embed_text(query)
    
    # 2. Search vector index for similar shots
    results = vector_index.search(
        query_vector=query_embedding,
        k=max_shots
    )
    
    # 3. Return shots ranked by semantic similarity
    return ranked_shots
```

**What ACTUALLY Happens**:
```python
def build_for_query(story_slug, query, max_shots=50):
    # 1. Get ALL shots from database
    all_shots = database.get_shots_by_story(story_slug)
    
    # 2. Score with basic keyword matching âŒ
    scored = self._score_shots(all_shots, query)
    
    # Line 125-137: Simple Jaccard similarity on words
    query_words = set(query.lower().split())
    asr_words = set(asr_text.split())
    score = len(query_words & asr_words) / len(query_words | asr_words)
    
    # 3. Return top N
    return scored[:max_shots]
```

**Why This Is Bad**:
- âŒ Ignores the 384d semantic embeddings we generated
- âŒ Ignores the 512d visual embeddings  
- âŒ Can't find semantically similar content with different wording
- âŒ Example: Query "football goal celebration" won't match "striker scores winner"
- âŒ Visual content is completely ignored (no CLIP search)

**The Comment in Code**:
```python
# Line 56-57 in working_set.py:
# Step 2: Perform vector similarity search
# TODO: Implement when embedder is integrated  â† âŒ EMBEDDER IS INTEGRATED!
```

---

### 3. Agent Processing: Works But Gets Poor Input

**Files**: `agent/planner.py`, `agent/picker.py`, `agent/verifier.py`

**Current Flow**:
```
Planner:
  1. Gets working set (50-100 shots) â† Based on keywords only
  2. Formats ALL shot details for Claude
  3. Claude sees: Gemini descriptions, transcripts, metadata
  4. Creates beat-by-beat plan
  â†“
Picker:
  1. For each beat, gets working set â† Again, keyword-based only
  2. Sends 20 shots per beat to Claude
  3. Claude selects best shots
  â†“
Verifier:
  1. Reviews selected shots
  2. Checks quality, pacing, narrative
  3. Scores 1-10, provides feedback
```

**The Issue**:
- Claude is smart and works well with what it gets
- BUT it only sees the shots that keyword matching found
- Many semantically relevant shots are never considered
- The LLM can't fix the upstream selection problem

---

## ğŸ¯ The Solution: Proper Semantic Search

### What Needs To Change

**File**: `agent/working_set.py` - Line 44-82

**Replace This**:
```python
def build_for_query(self, story_slug, query, max_shots=50):
    # Get ALL shots
    all_shots = self.database.get_shots_by_story(story_slug)
    
    # Score with keywords âŒ
    scored_shots = self._score_shots(all_shots, query)
    selected_shots = scored_shots[:max_shots]
```

**With This**:
```python
def build_for_query(self, story_slug, query, max_shots=50):
    # 1. Embed the query
    from ingest.embedder import Embedder
    embedder = Embedder(config)
    query_embedding = embedder.embed_text([query])[0]
    
    # 2. Search vector index
    results = self.vector_index.search(
        query_vector=query_embedding,
        k=max_shots * 2  # Get 2x for filtering
    )
    
    # 3. Fetch full shot details
    shot_ids = [r.shot_id for r in results]
    shots = self.database.get_shots_by_ids(shot_ids)
    
    # 4. Add semantic similarity scores
    for shot, result in zip(shots, results):
        shot['semantic_score'] = result.score
        shot['relevance_score'] = result.score * 10  # Scale to 0-10
    
    # 5. Optional: Boost with keyword overlap for hybrid search
    # ... existing keyword scoring as secondary signal
    
    return shots[:max_shots]
```

---

## ğŸ“ˆ Expected Improvements

### Before (Keyword Matching):
```
Query: "football goal celebration"

Results:
âœ“ Shot 23: "player scores goal"          (keyword: goal âœ“)
âœ“ Shot 45: "celebration in stadium"      (keyword: celebration âœ“)
âœ— Shot 67: "striker nets winner"         (âŒ no keyword match)
âœ— Shot 89: "team jubilation"             (âŒ no keyword match)
âœ— Shot 102: "fans cheering wildly"       (âŒ no keyword match)
```

### After (Semantic Search):
```
Query: "football goal celebration"

Results (by semantic similarity):
âœ“ Shot 23: "player scores goal"          (0.92 similarity)
âœ“ Shot 67: "striker nets winner"         (0.89 similarity)
âœ“ Shot 45: "celebration in stadium"      (0.87 similarity)
âœ“ Shot 89: "team jubilation"             (0.85 similarity)
âœ“ Shot 102: "fans cheering wildly"       (0.82 similarity)
```

---

## ğŸ”§ Additional Enhancements

### 1. Multimodal Search
```python
# Combine text + visual search
text_results = vector_index.text_index.search(text_query_embedding)
visual_results = vector_index.visual_index.search(visual_query_embedding)

# Weighted combination
combined_scores = (
    0.7 * text_results.scores + 
    0.3 * visual_results.scores
)
```

### 2. Hybrid Search
```python
# Best of both worlds:
semantic_score = vector_similarity(query, shot)
keyword_score = jaccard_similarity(query, shot)

final_score = 0.8 * semantic_score + 0.2 * keyword_score
```

### 3. Contextual Re-ranking
```python
# After semantic search, use Gemini descriptions for final ranking
for shot in candidates:
    context = f"Query: {query}\nShot: {shot.gemini_description}"
    relevance = llm.score_relevance(context)
    shot.final_score = 0.6 * semantic + 0.4 * relevance
```

---

## ğŸ“ Summary

### Current State:
- âœ… Embeddings generated correctly
- âœ… Vector index exists and works
- âœ… LLM agents are well-designed
- âŒ **Embeddings not used for search**
- âŒ Falls back to primitive keyword matching

### Impact:
- ğŸ”´ Many relevant shots never reach the LLM
- ğŸ”´ Agent decisions based on incomplete candidate set
- ğŸ”´ Output quality limited by upstream selection
- ğŸ”´ Expensive embeddings computed but wasted

### Fix Required:
1. Integrate embedder in `working_set.py`
2. Use `vector_index.search()` instead of keyword matching
3. Add hybrid scoring (semantic + keywords)
4. Consider multimodal search (text + visual)

### Expected Result:
- ğŸŸ¢ Semantically similar shots surface automatically
- ğŸŸ¢ Better candidate sets for LLM agents
- ğŸŸ¢ Higher quality final edits
- ğŸŸ¢ True intelligent video understanding
